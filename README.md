# Simula√ß√£o H√≠brida de Ecossistema (MPI + OpenMP)

Este projeto implementa uma simula√ß√£o distribu√≠da e paralelizada de um ecossistema utilizando uma arquitetura h√≠brida com **MPI (Message Passing Interface)** e **OpenMP**. 

O objetivo da simula√ß√£o √© modelar o comportamento de agentes aut√¥nomos (representando indiv√≠duos como pescadores ou coletores) que se movem por um grid espacial, consumindo recursos naturais que se regeneram sazonalmente. O projeto demonstra conceitos avan√ßados de Computa√ß√£o de Alto Desempenho (HPC), incluindo particionamento de dom√≠nio, troca de halos, migra√ß√£o de dados entre n√≥s de processamento e concorr√™ncia segura entre threads.

## üöÄ Tecnologias Utilizadas
* **C++** (Padr√£o C++17 recomendado)
* **MPI** (OpenMPI / MPICH) para paralelismo inter-n√≥s (mem√≥ria distribu√≠da).
* **OpenMP** para paralelismo intra-n√≥s (mem√≥ria compartilhada).

## ‚öôÔ∏è Arquitetura de Paraleliza√ß√£o

A simula√ß√£o foi dividida em duas camadas de paralelismo para maximizar a efici√™ncia computacional:

### 1. N√≠vel Distribu√≠do (MPI)
* **Particionamento de Dom√≠nio:** O grid global (2D) √© fatiado horizontalmente (1D Decomposition). Cada processo MPI √© respons√°vel por um subgrid cont√≠guo.
* **Troca de Halos (Ghost Cells):** A cada ciclo, as fronteiras dos subgrids s√£o sincronizadas utilizando `MPI_Sendrecv`. O padr√£o de comunica√ß√£o implementado √© o de *Shift Unidirecional* (Shift Up / Shift Down) para garantir consist√™ncia e evitar *deadlocks*.
* **Migra√ß√£o de Agentes:** Agentes que decidem se mover para fora dos limites do seu subgrid local s√£o empacotados e enviados para o processo vizinho correspondente atrav√©s da rede.

### 2. N√≠vel Local (OpenMP)
* **Processamento Massivo:** O processamento das decis√µes e da carga computacional sint√©tica (`execute_synthetic_load`) dos agentes √© feito em paralelo usando `#pragma omp parallel for`.
* **Consumo Thread-Safe:** O acesso e a dedu√ß√£o dos recursos do grid pelas threads s√£o protegidos por regi√µes cr√≠ticas (`#pragma omp critical`) para evitar *Race Conditions* (condi√ß√µes de corrida) quando m√∫ltiplos agentes caem na mesma c√©lula.
* **Regenera√ß√£o de Matriz:** A regenera√ß√£o sazonal do grid utiliza `#pragma omp parallel for collapse(2)` para otimizar o balanceamento de carga no acesso √† mem√≥ria bidimensional.
* **Redu√ß√£o para M√©tricas:** A coleta de m√©tricas globais utiliza a cl√°usula `reduction` do OpenMP em conjunto com o `MPI_Reduce` para garantir contagens exatas sem gargalos de sincroniza√ß√£o.

## üåç Regras do Ecossistema

1. **Sazonalidade:** O sistema alterna entre duas esta√ß√µes (`CHEIA` e `SECA`) a cada $S$ ciclos. Na esta√ß√£o cheia, os recursos regeneram rapidamente; na seca, o ambiente sofre colapso.
2. **Carga Sint√©tica:** Cada agente executa um volume de opera√ß√µes matem√°ticas atreladas √† quantidade de recurso da c√©lula, simulando o custo computacional real de processamento em HPC.
3. **Migra√ß√£o F√≠sica:** O esgotamento dos recursos em um n√≥ for√ßa os agentes a migrarem fisicamente na mem√≥ria para n√≥s adjacentes para evitar a inani√ß√£o.

## üõ†Ô∏è Compila√ß√£o e Execu√ß√£o

Para compilar o projeto, voc√™ precisar√° de um compilador C++ com suporte a MPI e OpenMP instalado no seu cluster ou ambiente de desenvolvimento (ex: `gcc`, `openmpi`).

### Compila√ß√£o
```bash
mpic++ -O3 -fopenmp main.cpp -o sim
```

(A flag -O3 √© recomendada para otimiza√ß√£o de performance da carga sint√©tica).
### Execu√ß√£o

Defina o n√∫mero de threads OpenMP por processo e execute com o mpirun ou mpiexec. Exemplo para rodar com 4 processos MPI, sendo 4 threads OpenMP por processo:
```bash
export OMP_NUM_THREADS=4
mpirun -np 4 ./sim
```
(Nota: Os par√¢metros do tamanho do grid (W,H), ciclos (T), tamanho da esta√ß√£o (S) e n√∫mero de agentes (N) podem ser ajustados na fun√ß√£o main()).

```
